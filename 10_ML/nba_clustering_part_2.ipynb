{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datascience import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means and NBA Data, Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains player statistics for the 2016 NBA season. Try k-means clustering on *subsets* of the columns in the dataset. Start with trying to answer the same questions as above. If you'd like, see if you can interpret the clusters when you increase the number of clusters.\n",
    "\n",
    "**Warning**: Don't use scatter_matrix with more than ~5 columns -- it requires a lot of memory to plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of this dataset are:\n",
    "\n",
    "```\n",
    "Rk        Player-id\n",
    "Player    Player Name\n",
    "Pos       Position\n",
    "Age       Player Age\n",
    "Tm        Team\n",
    "G         Number of Games played\n",
    "GS        Number of Games started\n",
    "MP        Minutes played\n",
    "FG        Field Goals\n",
    "FGA       Field Goals Attempted\n",
    "3P        Three-point shots made\n",
    "3PA       Three-point shots attempted\n",
    "2P        Two-point shots made\n",
    "2PA       Two-point shots attempted\n",
    "FT        Free Throws made\n",
    "FTA       Free Throws attempted\n",
    "ORB       Offensive rebounds\n",
    "DRB       Defensive rebounds\n",
    "TRB       Total rebounds\n",
    "AST       Number of assists\n",
    "STL       Number of steals\n",
    "BLK       Number of blocks\n",
    "TOV       Number of turnovers\n",
    "PF        Number of personal fouls\n",
    "PTS       Total number of points\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba = Table.read_table('data/nba2016.csv')\n",
    "nba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive clustering\n",
    "\n",
    "Try clustering without any scaling.\n",
    "\n",
    "### A data-driven approach to answering \"how many clusters are there?\"\n",
    "* Try kmeans clustering with 1,2,3,...,10 clusters.\n",
    "* For each clustering attempt, measure how well it's clustered.\n",
    "* Use the smallest number of clusters that give the most clustering accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_scores(data_arr):\n",
    "    '''\n",
    "    input a numpy nd.array of data\n",
    "    returns cluster quality scores of using 1,2,..,9 clusters\n",
    "    '''\n",
    "    scores = []\n",
    "    for i in np.arange(1, 10):\n",
    "        score = KMeans(n_clusters=i).fit(data_arr).score(data_arr)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_features = nba.drop('Rk', 'Player', 'Pos', 'Tm')\n",
    "\n",
    "scores = cluster_scores(clustering_features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the quality of the different clustering attempts\n",
    "* Look for the \"elbow\" in the plot, when increaseing the number of clusters no longer gives you better clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 10), scores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try using 2 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the attribute .values accesses the underlying numpy\n",
    "# array of a Table, which sklearn requires.\n",
    "train = nba.drop('Rk', 'Player', 'Pos', 'Tm').values\n",
    "\n",
    "kmeans2 = KMeans(n_clusters=2)\n",
    "labels2 = kmeans2.fit_predict(train)\n",
    "out2 = nba.with_column('label', labels2) # add labels to our input table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the clusters look like?\n",
    "* Group by label and look at the sizes of the clusters\n",
    "* Group by label and look at the average values of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2.group('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2.group('label', np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main differentiators seem to come from minutes played:\n",
    "* Most other statistics are correlated with minutes played! So MP explains the clusters well by itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2.hist('MP', group='label', unit='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try 3 clusters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = nba.drop('Rk', 'Player', 'Pos', 'Tm').values\n",
    "\n",
    "kmeans3 = KMeans(n_clusters=3)\n",
    "labels3 = kmeans3.fit_predict(train)\n",
    "out3 = nba.with_column('label', labels3) # add labels to our input table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the clusters represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3.group('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3.group('label', np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main differentiator still seems to be minutes played (`MP`), which isn't a surprise.\n",
    "* The three groups consist of \"small/medium/large\" number of minutes played.\n",
    "* There's a better description, though. The three clusters can be described as:\n",
    "    - Starters\n",
    "    - Second Unit\n",
    "    - Players with inconsistent playing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3.hist('MP', group='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3.hist('G', group='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3.hist('GS', group='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we try to recover player positions from clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba.group('Pos').sort('count', descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy for clustering players into positions played:\n",
    "* Make the dataset reflect the differences in how positions play\n",
    "\n",
    "To Start:\n",
    "* De-correlate player statistics from minutes played.\n",
    "* Drop `G`, `GS`, and `MP` -- since these don't have to do with your position!\n",
    "* Also try: scale the dataset appropriately (`StandardScaler`?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_normalize = nba.drop('Rk','Player','Pos','Age','Tm','G','GS','MP')\n",
    "min_played = nba.column('MP')\n",
    "\n",
    "features = to_normalize\n",
    "for label in to_normalize.labels:\n",
    "    features = features.with_column(label, nba.column(label) / min_played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cluster_scores(features.values)\n",
    "plt.plot(np.arange(1, 10), scores);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 4 clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "\n",
    "train = features.values\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "labels = kmeans.fit_predict(train)\n",
    "out = nba.with_column('label', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.group(['Pos', 'label']).pivot('Pos', 'label', 'count', sum).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.group('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.group('label', np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histograms/scatterplots for labels to assess the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    features\n",
    "    .with_column('label', labels)\n",
    "    .where('FTA', are.below(0.4))  # filter out james harden\n",
    "    .scatter('FTA', 'DRB', colors='label')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.hist('3P', group='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "ssfeatures = ss.fit_transform(features.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cluster_scores(ssfeatures)\n",
    "plt.plot(np.arange(1, 10), scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "\n",
    "train = ssfeatures\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "labels = kmeans.fit_predict(train)\n",
    "out = nba.with_column('label', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better:\n",
    "   * Centers are isolated to one cluster (along with most Power Forwards)\n",
    "   * Small forwards and guards are split between the other two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.group(['Pos', 'label']).pivot('Pos', 'label', 'count', sum).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What differentiates the other two?\n",
    "* Plot histograms and scatter-plots!\n",
    "* Look at who the outliers are.\n",
    "    - which players are assigned clusters that don't match their positions?\n",
    "    - An example may be Lebron James has stats that look like both a Forward and a Guard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.group('label', np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "* Remove extraneous columns\n",
    "* Add columns for efficiency (e.g. FG/FGA)\n",
    "* Add assist-turnover ratio (i.e. AST/TOV)\n",
    "* Forget trying to capture positions:\n",
    "    - Use only certain subsets and see what type of clusters you get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE\n",
    "\n",
    "Another clustering algorithm is called \"t-distributed stochastic neighbor embedding\", or TSNE for short. It attempts to embed high-dimensional datasets into low dimensions, while preserving regions of high-density.\n",
    "\n",
    "See a nice explanation here: https://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2) # embeds in the plane -- 2 dimensions\n",
    "tsne_out = tsne.fit_transform(ssfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    Table(['1', '2'])\n",
    "    .with_rows(out)\n",
    "    .with_columns('label', labels)\n",
    "    .scatter('1', '2', colors='label')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: clustering SDPD data\n",
    "\n",
    "A cleaned version of the SDPD data is found at `data/sdpd_clean.csv`. Try clustering these and understanding the clusters.\n",
    "\n",
    "As clustering algorithms require only numeric input, categorical data has been cleaned in a standard way. Yes/No fields have been changed to 1/0. \n",
    "\n",
    "The ethnicities are encoded with integers according to the following map:\n",
    "\n",
    "```\n",
    " 'W': 0,\n",
    " 'H': 1,\n",
    " 'B': 2,\n",
    " 'O': 3,\n",
    " 'A': 4,\n",
    " 'F': 5,\n",
    " 'V': 6,\n",
    " 'C': 7,\n",
    " 'I': 8,\n",
    " 'X': 9,\n",
    " 'K': 10,\n",
    " NAN: 11,\n",
    " 'P': 12,\n",
    " 'J': 13,\n",
    " 'Z': 14,\n",
    " 'L': 15,\n",
    " 'D': 16,\n",
    " 'S': 17,\n",
    " 'G': 18,\n",
    " 'U': 19\n",
    "```\n",
    "\n",
    "What are the implications of such a transformation of features? (hint: think about the distance function).\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
